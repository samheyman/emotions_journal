### Privacy

All inference runs on-device via WebAssembly. No data is transmitted to any server. The model is downloaded once and cached locally in the browser's IndexedDB.
